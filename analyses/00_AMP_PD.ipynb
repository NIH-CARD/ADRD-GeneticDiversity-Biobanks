{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9fb27483",
   "metadata": {},
   "source": [
    "# AMP-PD\n",
    "\n",
    "* **Project:** ADRD Genetic Diversity in Biobanks\n",
    "* **Version:** Python/3.9 and 3.10\n",
    "* **Last Updated:** 22-August-2024\n",
    "\n",
    "## Notebook Overview\n",
    "Check variants, APOE genotyping, define cases/controls by ancestry, demographic data, resilience/protective variants"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a8b6bff",
   "metadata": {},
   "source": [
    "# Query AMP PD to check for variants of interest "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c52b16e2",
   "metadata": {},
   "source": [
    "## Variables used \n",
    "- `${ANCESTRY}` = EUR, AFR, AMR, AAC, AJ, MDE, SAS, CAS, EAS, FIN, CAH\n",
    "- `${COHORT}` = AD, Dementia, Control or Case, Control\n",
    "- `${COUNT}` = Number of total individuals in each ancestry\n",
    "- `chr${}:Position:A1:A2` = Chromosome number, position, reference and alternative alleles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f14227f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd51b599-669c-4867-97b2-47cf3fcb3364",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile allvar_keep.txt\n",
    "chr${}:${Position}:${A1}:${A2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51b8bd89-cbae-44a1-a9cd-84318ec4a70a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "plink2 --pfile ${WORK_DIR}/FILTERED.AMP_PD_${ANCESTRY} \\\n",
    "--extract allvar_keep.txt --make-bed --out AMPDLB_vars_all_${ANCESTRY}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "672b02ae-d2ad-4709-a60a-9fe07d22e7b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "module load plink/1.9\n",
    "plink --bfile AMPDLB_vars_all_${ANCESTRY} --freq --out AMPDLB_vars_all_${ANCESTRY}_freq\n",
    "cat AMPDLB_vars_all_${ANCESTRY}_freq.frq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db6241e9-8610-49b9-8d83-3ed13a0a5970",
   "metadata": {},
   "outputs": [],
   "source": [
    "qc_covar_DLB = pd.read_csv(\"${WORK_DIR}/COVFILE.csv\", sep=\",\")\n",
    "qc_covar_DLB.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06a5591b-432d-4b3d-9028-79b5bad6b963",
   "metadata": {},
   "outputs": [],
   "source": [
    "qc_case_DLB = qc_covar_DLB[qc_covar_DLB[\"DLB_PHENO\"]==2]\n",
    "qc_case_DLB.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "8c302037-9e78-4491-bb4f-be1efe4628e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "qc_case_DLB_plink = qc_case_DLB[[\"ID\"]]\n",
    "qc_case_DLB_plink.to_csv(\"qc_case_DLB_plink.txt\", sep=\",\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "42800e95-e778-4253-9874-1f1824ef1947",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!awk '{print $0, $1}' qc_case_DLB_plink.txt > qc_case_DLB_ID_ID_plink.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e294db6d-d5c4-49cd-90ec-902ebfef827a",
   "metadata": {},
   "outputs": [],
   "source": [
    "qc_control_DLB = qc_covar_DLB[qc_covar_DLB[\"DLB_PHENO\"]==1]\n",
    "qc_control_DLB.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "e588ea41-3711-4aa7-ac1c-b24bba004418",
   "metadata": {},
   "outputs": [],
   "source": [
    "qc_control_DLB_plink = qc_control_DLB[[\"ID\"]]\n",
    "qc_control_DLB_plink.to_csv(\"qc_control_DLB_plink.txt\", sep=\",\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "9219a81d-3a3a-4efb-8afb-a4b4f5aefdbb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!awk '{print $0, $1}' qc_control_DLB_plink.txt > qc_control_DLB_ID_ID_plink.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c5e2689-49fa-406b-abca-e3f58ee9f67e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "module load plink/1.9\n",
    "plink --bfile AMPDLB_vars_all_${ANCESTRY} --keep qc_${COHORT}_DLB_ID_ID_plink.txt --make-bed --out AMPDLB_vars_all_${ANCESTRY}_${COHORT}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46c8c7cb-3c0f-4967-983f-7ceb7f909960",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "module load plink/1.9\n",
    "plink --bfile AMPDLB_vars_all_${ANCESTRY}_${COHORT} --freq --out AMPDLB_vars_all_${ANCESTRY}_${COHORT}\n",
    "cat AMPDLB_vars_all_${ANCESTRY}_${COHORT}.frq"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e76887d",
   "metadata": {},
   "source": [
    "# Query AMP PD for APOE genotyping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4600dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "from functools import reduce\n",
    "import argparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62fb9716",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile var_keepapoe.txt\n",
    "chr19:44908684:T:C\n",
    "chr19:44908822:C:T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb39def8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "module load plink\n",
    "plink2 --pfile ${WORK_DIR}/FILTERED.AMP_PD_${ANCESTRY} \\\n",
    "--extract var_keepapoe.txt --make-bed --out AMP_PD_vars_${ANCESTRY}_apoe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77fa01f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "module load plink/1.9\n",
    "plink --bfile AMP_PD_vars_${ANCESTRY}_apoe --keep qc_${COHORT}_DLB_ID_ID_plink.txt --make-bed --out AMP_DLB_vars_${ANCESTRY}_apoe_${COHORT}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71b7eac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "module load plink/1.9\n",
    "plink --bfile AMP_DLB_vars_${ANCESTRY}_apoe_${COHORT} --recode compound-genotypes --out AMP_DLB_vars_${ANCESTRY}_apoe_${COHORT}_recode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c95bb98",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile APOE_genotypes_PLINK_ped.py\n",
    "#!/bin/env python\n",
    "\n",
    "# Determine APOE genotypes from PLINK output\n",
    "    # January 2021\n",
    "    # Mary B. Makarious, Makayla Portley, and Cornelis Blauwendraat (LNG/NIA/NINDS/NIH)\n",
    "    # Script usage:\n",
    "        # python APOE_genotypes_PLINK_ped.py -i INPUT.ped -o OUTPUT_NAME\n",
    "\n",
    "## APOE Information\n",
    "# https://www.snpedia.com/index.php/APOE\n",
    "\n",
    "    # |          APOE GENO         \t| rs429358 \t| rs7412 \t|             COMBINED             \t|\n",
    "    # |:--------------------------:\t|:--------:\t|:------:\t|:--------------------------------:\t|\n",
    "    # |            e1/e1           \t|    CC    \t|   TT   \t|               CC_TT              \t|\n",
    "    # |            e1/e2           \t|    CT    \t|   TT   \t|          CT_TT or TC_TT          \t|\n",
    "    # |            e1/e4           \t|    CC    \t|   CT   \t|          CC_CT or CC_TC          \t|\n",
    "    # |            e2/e2           \t|    TT    \t|   TT   \t|               TT_TT              \t|\n",
    "    # |            e2/e3           \t|    TT    \t|   TC   \t|          TT_TC or TT_CT          \t|\n",
    "    # | e2/e4 or e1/e3 (Ambiguous) \t|    TC    \t|   TC   \t| TC_TC or CT_CT or TC_CT or CT_TC \t|\n",
    "    # |            e3/e3           \t|    TT    \t|   CC   \t|               TT_CC              \t|\n",
    "    # |            e3/e4           \t|    TC    \t|   CC   \t|          TC_CC or CT_CC          \t|\n",
    "    # |            e4/e4           \t|    CC    \t|   CC   \t|               CC_CC              \t|\n",
    "\n",
    "# Import the necessary packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "from functools import reduce\n",
    "import argparse\n",
    "\n",
    "# Initialize parser and add arguments\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"--input\", \"-i\", help=\"Input file name (with suffix)\")\n",
    "parser.add_argument(\"--output\", \"-o\", help=\"Desired output name (without suffix)\")\n",
    "args = parser.parse_args()\n",
    "\n",
    "# Read in the .ped file and force column names\n",
    "header_text = [\"FID\", \"IID\", \"PAT\", \"MAT\", \"SEX\", \"PHENO\", \"rs429358\", \"rs7412\"]\n",
    "input_ped_df = pd.read_csv(args.input, sep = \" \", header=None, names=header_text)\n",
    "\n",
    "# Make a combined column, gluing the genotypes from the rs429358 and rs7412 columns\n",
    "input_ped_df['rs429358_rs7412'] = input_ped_df['rs429358'].astype(str)+'_'+input_ped_df['rs7412']\n",
    "\n",
    "# Initialize a dictionary with the genotypes to search what genotype the alleles generate\n",
    "apoe_genotypes_dict = {\n",
    "    'CC_TT' : 'e1/e1',\n",
    "    'CT_TT' : 'e1/e2',\n",
    "    'TC_TT' : 'e1/e2',\n",
    "    'CC_CT' : 'e1/e4',\n",
    "    'CC_TC' : 'e1/e4',\n",
    "    'TT_TT' : 'e2/e2',\n",
    "    'TT_TC' : 'e2/e3',\n",
    "    'TT_CT' : 'e2/e3',\n",
    "    'TC_TC' : 'e2/e4 or e1/e3',\n",
    "    'CT_CT' : 'e2/e4 or e1/e3',\n",
    "    'TC_CT' : 'e2/e4 or e1/e3',\n",
    "    'CT_TC' : 'e2/e4 or e1/e3',\n",
    "    'TT_CC' : 'e3/e3',\n",
    "    'TC_CC' : 'e3/e4',\n",
    "    'CT_CC' : 'e3/e4',\n",
    "    'CC_CC' : 'e4/e4'\n",
    "}\n",
    "\n",
    "# Map the combined column to the dictionary to extract the genotypes\n",
    "input_ped_df['APOE_GENOTYPE'] = input_ped_df['rs429358_rs7412'].map(apoe_genotypes_dict)\n",
    "\n",
    "# If any of the combined alleles weren't in the dictionary, the dataframe now has NaN values\n",
    "# This happens if you have a 0 or missingness somewhere, resulting in an unsure genotype call\n",
    "# Replace these with something more useful, and state the APOE genotype as \"unknown\"\n",
    "input_ped_df.replace(np.nan, 'unknown', regex=True, inplace=True)\n",
    "\n",
    "# Make a file of just the FID, IID, SEX, PHENO, and APOE genotype\n",
    "subset_geno_df = input_ped_df.drop(columns=['PAT', 'MAT', 'rs429358', 'rs7412'])\n",
    "\n",
    "## Generate counts\n",
    "# Generate APOE genotype counts and percentages for entire dataset\n",
    "counts_df = pd.DataFrame(subset_geno_df['APOE_GENOTYPE'].value_counts().reset_index())\n",
    "counts_df.columns = ['APOE_GENOTYPE', 'TOTAL_COUNT']\n",
    "counts_df['TOTAL_PERCENT'] = counts_df['TOTAL_COUNT'] / subset_geno_df.shape[0] * 100\n",
    "\n",
    "# Separate out into cases, controls, and missing phenotypes\n",
    "    # This assumes controls=1 and cases=2 (missing is -9)\n",
    "\n",
    "# Subset by phenotype\n",
    "missing_pheno_df = subset_geno_df[subset_geno_df['PHENO'] == -9]\n",
    "controls_df = subset_geno_df[subset_geno_df['PHENO'] == 1]\n",
    "cases_df = subset_geno_df[subset_geno_df['PHENO'] == 2]\n",
    "\n",
    "# Generate APOE genotype counts and percentages for missing phenotypes\n",
    "missing_pheno_counts_df = pd.DataFrame(missing_pheno_df['APOE_GENOTYPE'].value_counts().reset_index())\n",
    "missing_pheno_counts_df.columns = ['APOE_GENOTYPE', 'MISSING_PHENO_COUNT']\n",
    "missing_pheno_counts_df['MISSING_PHENO_PERCENT'] = missing_pheno_counts_df['MISSING_PHENO_COUNT'] / missing_pheno_df.shape[0] * 100\n",
    "\n",
    "# Generate APOE genotype counts and percentages for controls\n",
    "controls_counts_df = pd.DataFrame(controls_df['APOE_GENOTYPE'].value_counts().reset_index())\n",
    "controls_counts_df.columns = ['APOE_GENOTYPE', 'CONTROLS_COUNT']\n",
    "controls_counts_df['CONTROLS_PERCENT'] = controls_counts_df['CONTROLS_COUNT'] / controls_df.shape[0] * 100\n",
    "\n",
    "# Generate APOE genotype counts and percentages for cases\n",
    "cases_counts_df = pd.DataFrame(cases_df['APOE_GENOTYPE'].value_counts().reset_index())\n",
    "cases_counts_df.columns = ['APOE_GENOTYPE', 'CASES_COUNT']\n",
    "cases_counts_df['CASES_PERCENT'] = cases_counts_df['CASES_COUNT'] / cases_df.shape[0] * 100\n",
    "\n",
    "# Merge the dataframes together for final summary counts file\n",
    "dataframes_tomerge = [counts_df, missing_pheno_counts_df, controls_counts_df, cases_counts_df]\n",
    "merged_summary_df = reduce(lambda left,right: pd.merge(left,right,on='APOE_GENOTYPE'), dataframes_tomerge)\n",
    "\n",
    "## Export\n",
    "complete_df_output = args.output + \".APOE_GENOTYPES.csv\"\n",
    "counts_df_output = args.output + \".APOE_SUMMARY.csv\"\n",
    "\n",
    "# Save out the complete dataframe as a .csv\n",
    "print(f\"Your complete genotype file has been saved here: {complete_df_output}\")\n",
    "subset_geno_df.to_csv(complete_df_output, index=False)\n",
    "\n",
    "# Save out the counts as a .csv\n",
    "print(f\"The summary counts have been saved here: {counts_df_output}\")\n",
    "merged_summary_df.to_csv(counts_df_output, index=False)\n",
    "\n",
    "# Done!\n",
    "print(\"Thanks!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ddf704a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "python APOE_genotypes_PLINK_ped.py -i AMP_DLB_vars_${ANCESTRY}_apoe_${COHORT}_recode.ped -o AMP_DLB_vars_${ANCESTRY}_apoe_${COHORT}_recode.ped_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9e0e878",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the data into a pandas DataFrame\n",
    "file_path = '${WORK_DIR}/AMP_DLB_vars_${ANCESTRY}_apoe_${COHORT}_recode.ped_test.APOE_GENOTYPES.csv'  \n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Define the order of genotypes\n",
    "genotype_order = [\n",
    "    \"e1/e1\", \"e1/e2\", \"e1/e4\", \"e2/e2\", \"e2/e3\", \"e2/e4 or e1/e3\",\n",
    "    \"e3/e3\", \"e3/e4\", \"e4/e4\"\n",
    "]\n",
    "\n",
    "# Count the occurrences of each genotype\n",
    "genotype_counts = df['APOE_GENOTYPE'].value_counts()\n",
    "\n",
    "# Initialize the counts for the genotypes in the specified order\n",
    "genotype_counts_ordered = {genotype: 0 for genotype in genotype_order}\n",
    "\n",
    "# Fill the counts for the observed genotypes\n",
    "for genotype in genotype_counts.index:\n",
    "    if genotype in genotype_counts_ordered:\n",
    "        genotype_counts_ordered[genotype] = genotype_counts[genotype]\n",
    "    elif genotype == \"e2/e4\" or genotype == \"e1/e3\":\n",
    "        genotype_counts_ordered[\"e2/e4 or e1/e3\"] += genotype_counts[genotype]\n",
    "\n",
    "# Add the total count\n",
    "total_count = df.shape[0]\n",
    "\n",
    "# Print the results with percentages\n",
    "print(\"Genotype\\tCount\\tPercentage\")\n",
    "for genotype in genotype_order:\n",
    "    count = genotype_counts_ordered[genotype]\n",
    "    percentage = (count / total_count) * 100\n",
    "    print(f\"{genotype}\\t{count} ({percentage:.2f}%)\")\n",
    "print(f\"Total\\t{total_count} (100.00%)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc5914b5",
   "metadata": {},
   "source": [
    "# Query AMP PD to define cases and controls in each ancestry and obtain demographic and phenotyp data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87bee8ec",
   "metadata": {},
   "source": [
    "## Define cases and controls in each ancestry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e85df272",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ee5da02",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "plink2 --pfile ${WORK_DIR}/FILTERED.AMP_PD_${ANCESTRY} \\\n",
    "--keep qc_${COHORT}_DLB_ID_ID_plink.txt --make-bed --out AMPDLB_${ANCESTRY}_${COHORT}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "837eeda6",
   "metadata": {},
   "source": [
    "## Demographic and phenotype data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87378bc3",
   "metadata": {},
   "source": [
    "##### These codes were replicated for cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04e4b910",
   "metadata": {},
   "outputs": [],
   "source": [
    "qc_covarsex = pd.read_csv(\"${WORK_DIR}/COVFILE.csv\", sep=\",\")\n",
    "qc_covarsex.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f2c715d",
   "metadata": {},
   "outputs": [],
   "source": [
    "qc_controlsex = qc_covarsex[qc_covarsex[\"DLB_PHENO\"]==1]\n",
    "qc_controlsex.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22d45439",
   "metadata": {},
   "outputs": [],
   "source": [
    "qc_controlsex.to_csv('qc_controlsex_file.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "436d9546",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cut -f 1 AMPDLB_${ANCESTRY}_control.fam > first_column${ANCESTRY}.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0c38a54",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat first_columnAAC.txt first_columnAMR.txt first_columnFIN.txt first_columnCAS.txt first_columnMDE.txt first_columnAFR.txt first_columnEAS.txt first_columnAJ.txt first_columnSAS.txt first_columnEUR.txt first_columnCAH.txt > merged_file.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88e4511c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!awk -F ',' 'NR==FNR{a[$1]; next} FNR==1 {print} $1 in a' merged_file.txt qc_controlsex_file.csv > filtered_qc_controlsex_file.csv\n",
    "!awk -F',' 'NR==1 {print $0 > \"header.csv\"; next} $2 == 1 {print $0 > \"controlmale2.csv\"} $2 == 2 {print $0 > \"controlfemale2.csv\"}' filtered_qc_controlsex_file.csv\n",
    "!awk -F',' 'NR>1 {sum += $3; sumsq += ($3)^2} END {mean = sum/NR; sd = sqrt(sumsq/NR - (sum/NR)^2); print \"Mean age:\", mean; print \"Standard deviation of age:\", sd}' controlmale2.csv\n",
    "!awk -F',' 'NR>1 {sum += $3; sumsq += ($3)^2} END {mean = sum/NR; sd = sqrt(sumsq/NR - (sum/NR)^2); print \"Mean age:\", mean; print \"Standard deviation of age:\", sd}' controlfemale2.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6ff1872",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "module load plink/1.9\n",
    "plink --bfile AMPDLB_${ANCESTRY}_${COHORT}  --recodeA  --out AMPDLB_${ANCESTRY}_${COHORT}_recode\n",
    "awk '${COLUMN} == 1' AMPDLB_${ANCESTRY}_${COHORT}_recode.raw  > AMPDLB_${ANCESTRY}_${COHORT}_recode.raw.filtered.raw"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cceca00a",
   "metadata": {},
   "source": [
    "# Query AMP PD for resilience and protective variants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dbc5f27",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "from functools import reduce\n",
    "import argparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51f32db7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile var_keepprotect.txt\n",
    "    chr${}:${Position}:${A1}:${A2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f29a74c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "module load plink\n",
    "plink2 --pfile ${WORK_DIR}/FILTERED.AMP_PD_${Ancestry} \\\n",
    "--extract var_keepprotect.txt --make-bed --out AMP_PD_vars_${Ancestry}_pro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e529338d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "module load plink/1.9\n",
    "plink --bfile AMP_PD_vars_${Ancestry}_pro --keep ${WORK_DIR}/qc_${COHORT}_DLB_ID_ID_plink.txt --make-bed --out AMP_DLB_vars_${Ancestry}_pro_${COHORT}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32356e58",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "module load plink/1.9\n",
    "plink --bfile AMP_DLB_vars_${Ancestry}_pro_${COHORT} --recodeA --out AMP_DLB_vars_${Ancestry}_pro_${COHORT}_txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b06ae94",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Define file paths and ancestries\n",
    "ancestries = ['FIN', 'EUR', 'AFR', 'AMR', 'EAS', 'SAS', 'MDE', 'AJ', 'AAC', 'CAS', 'CAH']\n",
    "base_case_file = 'AMP_DLB_vars_{ancestry}_pro_${COHORT}_txt.raw'\n",
    "base_apoe_file = '${WORK_DIR}/AMP_DLB_vars_{ancestry}_apoe_${COHORT}_recode.ped_test.APOE_GENOTYPES.csv'\n",
    "\n",
    "# Initialize an empty list to collect DataFrames\n",
    "all_results = []\n",
    "\n",
    "for ancestry in ancestries:\n",
    "    # Generate the specific file paths for each ancestry\n",
    "    case_file = base_case_file.format(ancestry=ancestry)\n",
    "    apoe_file = base_apoe_file.format(ancestry=ancestry)\n",
    "\n",
    "    # Check if both files exist\n",
    "    if not os.path.exists(case_file):\n",
    "        print(f\"Case file for {ancestry} not found, skipping...\")\n",
    "        continue\n",
    "    if not os.path.exists(apoe_file):\n",
    "        print(f\"APOE genotype file for {ancestry} not found, skipping...\")\n",
    "        continue\n",
    "\n",
    "    # Load the genotype data\n",
    "    case_df = pd.read_csv(case_file, delim_whitespace=True)\n",
    "\n",
    "    # Load the APOE genotype file\n",
    "    apoe_df = pd.read_csv(apoe_file)\n",
    "    apoe_df = apoe_df[['FID', 'IID', 'APOE_GENOTYPE']]\n",
    "\n",
    "    # Merge the genotype data with APOE genotypes\n",
    "    case_merged_df = case_df.merge(apoe_df, on=['FID', 'IID'], how='left')\n",
    "\n",
    "    # Create the output DataFrame\n",
    "    output_df = pd.DataFrame()\n",
    "    output_df['genotype'] = case_merged_df['APOE_GENOTYPE']\n",
    "    output_df['ancestry'] = ancestry\n",
    "\n",
    "    # Combine variant information into a single column\n",
    "    variant_cols = [col for col in case_df.columns if ':' in col]  # Select columns that represent variants\n",
    "    variation_list = []\n",
    "    for idx, row in case_merged_df.iterrows():\n",
    "        sample_variations = []\n",
    "        for col in variant_cols:\n",
    "            genotype = row[col]\n",
    "            if genotype != 0:  # Exclude wild-type (0) genotypes\n",
    "                sample_variations.append(f\"{col}_{genotype}\")\n",
    "        variation_list.append(sample_variations if sample_variations else [\"No Variations\"])\n",
    "\n",
    "    # Explode the variations into separate rows\n",
    "    exploded_df = output_df.loc[output_df.index.repeat([len(v) for v in variation_list])].reset_index(drop=True)\n",
    "    exploded_df['variation'] = [var for sublist in variation_list for var in sublist]\n",
    "\n",
    "    # Remove trailing numbers and count occurrences\n",
    "    exploded_df['variation'] = exploded_df['variation'].str.replace(r'_\\d+$', '', regex=True)  # Remove trailing numbers\n",
    "    count_df = exploded_df.groupby(['genotype', 'ancestry', 'variation']).size().reset_index(name='count')\n",
    "\n",
    "    # Append the current ancestry results to the list\n",
    "    all_results.append(count_df)\n",
    "\n",
    "# Concatenate all results into a single DataFrame\n",
    "final_results = pd.concat(all_results, ignore_index=True)\n",
    "\n",
    "# Save the combined results to a single output file\n",
    "combined_output_file = 'combined_${COHORT}_final_output.csv'\n",
    "final_results.to_csv(combined_output_file, index=False)\n",
    "\n",
    "print(f\"Combined output saved to {combined_output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cd9feb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Read the CSV file into a pandas DataFrame\n",
    "df = pd.read_csv('combined_${COHORT}_final_output.csv')\n",
    "\n",
    "# Define the desired order of genotypes\n",
    "genotype_order = [\n",
    "    'unknown_unknown',\n",
    "    'e1/e1',\n",
    "    'e1/e2',\n",
    "    'e1/e4',\n",
    "    'e2/e2',\n",
    "    'e2/e3',\n",
    "    'e2/e4 or e1/e3',\n",
    "    'e3/e3',\n",
    "    'e3/e4',\n",
    "    'e4/e4',\n",
    "]\n",
    "\n",
    "# Define the new order of columns\n",
    "new_column_order = ['EUR', 'AFR', 'AMR', 'EAS', 'SAS', 'MDE', 'AJ', 'FIN', 'AAC', 'CAS', 'CAH']\n",
    "\n",
    "# Define the total numbers for each ancestry\n",
    "total_numbers = {\n",
    "    'EUR': ${count},\n",
    "    'AFR': ${count},\n",
    "    'AMR': ${count},\n",
    "    'EAS': ${count},\n",
    "    'SAS': ${count},\n",
    "    'MDE': ${count},\n",
    "    'AJ': ${count},\n",
    "    'FIN': ${count},\n",
    "    'AAC': ${count},\n",
    "    'CAS': ${count},\n",
    "    'CAH': ${count}\n",
    "}\n",
    "\n",
    "# Create a directory to save the tables if it doesn't exist\n",
    "output_dir = 'variant_tables'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Iterate over unique variations\n",
    "for variation in df['variation'].unique():\n",
    "    # Create a subset of the DataFrame for the current variation\n",
    "    subset = df[df['variation'] == variation]\n",
    "\n",
    "    # Pivot the subset to create the desired table\n",
    "    pivot_table = subset.pivot_table(index='genotype', columns='ancestry', values='count', fill_value=0)\n",
    "\n",
    "    # Ensure the index is in the specified genotype order\n",
    "    pivot_table = pivot_table.reindex(genotype_order)\n",
    "\n",
    "    # Reorder the columns\n",
    "    pivot_table = pivot_table.reindex(columns=new_column_order)\n",
    "\n",
    "    # Create a DataFrame for the total numbers and concatenate it as the last row\n",
    "    total_df = pd.DataFrame(total_numbers, index=['total'])\n",
    "    pivot_table = pd.concat([pivot_table, total_df])\n",
    "\n",
    "    # Fill NaN values with 0 before converting to integers\n",
    "    pivot_table = pivot_table.fillna(0).astype(int)\n",
    "\n",
    "    # Calculate the percentage for each value, ignoring division by zero errors\n",
    "    percentage_table = pivot_table.div(pivot_table.loc['total'], axis=1).replace([float('inf'), -float('inf'), float('nan')], 0) * 100\n",
    "\n",
    "    # Convert integer values to strings for the formatted table\n",
    "    formatted_values = pivot_table.astype(str)\n",
    "\n",
    "    # Combine values and percentages, replacing \"0 (nan%)\" or \"0 (0%)\" with just \"0\"\n",
    "    formatted_table = formatted_values + \" (\" + percentage_table.round(2).astype(str) + \"%)\"\n",
    "    formatted_table = formatted_table.replace(r'0 \\(nan%\\)', '0', regex=True)\n",
    "    formatted_table = formatted_table.replace(r'0 \\(0.0%\\)', '0', regex=True)\n",
    "\n",
    "    # Format the 'total' row to display only values, not percentages\n",
    "    formatted_table.loc['total'] = formatted_values.loc['total']\n",
    "\n",
    "    # Save the formatted table to a CSV file\n",
    "    output_file_path = os.path.join(output_dir, f'pivot_table_{variation}_value_percentage.csv')\n",
    "    formatted_table.to_csv(output_file_path)\n",
    "\n",
    "    print(f'Saved value and percentage pivot table for Variation: {variation} to {output_file_path}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
