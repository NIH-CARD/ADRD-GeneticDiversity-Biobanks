{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f48f4bda",
   "metadata": {},
   "source": [
    "# ADSP\n",
    "\n",
    "* **Project:** ADRD Genetic Diversity in Biobanks\n",
    "* **Version:** Python/3.9 and 3.10\n",
    "* **Last Updated:** 22-August-2024\n",
    "\n",
    "## Notebook Overview\n",
    "Check variants, allele freqs, calculate missingness, APOE genotyping, demographic data, resilience/protective variants"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f3c15dd",
   "metadata": {},
   "source": [
    "# Query ADSP to check for variants of interest, allele frequency, and to calculate missingness"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cdf597d",
   "metadata": {},
   "source": [
    "## Variables used \n",
    "- `${ANCESTRY}` = EUR, AFR, AMR, AAC, AJ, MDE, SAS, CAS, EAS, FIN, CAH\n",
    "- `${COHORT}` = AD, Dementia, Control or Case, Control\n",
    "- `${COUNT}` = Number of total individuals in each ancestry\n",
    "- `${GENOTYPE}` = Different APOE genotypes\n",
    "- `chr${}:Position:A1:A2` = Chromosome number, position, reference and alternative alleles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eaf304e2-6cfe-4a98-b211-ea94aa0a3278",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a58cee54-71e6-42ba-82f1-8130fe8d9912",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Check if the variants exist in the data or not\n",
    "!grep -e \"chr${}:position:A1:A2\"  ${WORK_DIR}/chr${}.compact_filtered.r4.wgs.biallelic.pvar > new_output.txt \n",
    "!cat new_output.txt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34eed212-3208-42dd-a152-57486a71f7ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "module load plink\n",
    "plink2 -pfile ${WORK_DIR}/chr${}.compact_filtered.r4.wgs.biallelic --snps chr${}:position:A1:A2 --make-pgen --out new_chr${}vars_UKB\n",
    "cat new_chr${}vars_UKB.pvar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71f986f8-c9c5-42f9-a6fc-080a8a95586a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Check missingness\n",
    "%%bash\n",
    "module load plink\n",
    "plink2 -pfile new_chr${}vars_UKB --missing --out new_chr${}vars_UKB_missing\n",
    "cat new_chr${}vars_UKB_missing.vmiss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72efdaed-7331-4170-84ed-a0f7b5b39c06",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Check frequency\n",
    "%%bash\n",
    "module load plink\n",
    "plink2 --pfile new_chr${}vars_UKB --freq --out new_chr${}vars_UKB_freq\n",
    "cat new_chr${}vars_UKB_freq.afreq"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7072e7c5",
   "metadata": {},
   "source": [
    "## Keep only individuals who have variants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d688e5ff-89eb-451f-909a-cbf08f1f0f50",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/bin/bash\n",
    "\n",
    "# Load PLINK module\n",
    "module load plink\n",
    "# Define the variants\n",
    "variants=(\"chr${}:position:A1:A2\")\n",
    "\n",
    "# Define the files\n",
    "files=(\"chr${}.compact_filtered.r4.wgs.biallelic\")\n",
    "\n",
    "# Create a folder to store extracted data\n",
    "mkdir -p extracted_data_UKB\n",
    "\n",
    "# Loop over each file\n",
    "for file in \"${files[@]}\"; do\n",
    "    # Create a subfolder for each file\n",
    "    mkdir -p extracted_data_UKB/${file}\n",
    "    \n",
    "    # Loop over each variant and extract it\n",
    "    for variant in \"${variants[@]}\"; do\n",
    "        # Create a temporary file for the variant\n",
    "        echo \"$variant\" > temp_variant.txt\n",
    "        \n",
    "        # Run PLINK command\n",
    "        plink2 --pfile ${WORK_DIR}/${file} --extract temp_variant.txt --make-bed --out extract_${file}_${variant}\n",
    "        \n",
    "        # Move the extracted files to the subfolder\n",
    "        mv extract_${file}_${variant}.bed extracted_data_UKB/${file}/\n",
    "        mv extract_${file}_${variant}.bim extracted_data_UKB/${file}/\n",
    "        mv extract_${file}_${variant}.fam extracted_data_UKB/${file}/\n",
    "    done\n",
    "done\n",
    "\n",
    "# Clean up temporary file\n",
    "rm temp_variant.txt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1d3516f-210f-44b4-814b-3e7ee1718bf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/bin/bash\n",
    "\n",
    "# Load PLINK module\n",
    "module load plink\n",
    "\n",
    "plink2 --bfile ${WORK_DIR}/chr${}.compact_filtered.r4.wgs.biallelic/extract_chr${}.compact_filtered.r4.wgs.biallelic_chr${}:position:A1:A2  --recode A --out extract_chr${}.compact_filtered.r4.wgs.biallelic_chr${}:position:A1:A2_recoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2e327e7b-cc58-4f8f-8d58-af0e3e9d5123",
   "metadata": {},
   "outputs": [],
   "source": [
    "awk '$7 == 0 || $7 == 1' extract_chr${}.compact_filtered.r4.wgs.biallelic_chr${}:position:A1:A2_recoded.raw  > extract_chr${}.compact_filtered.r4.wgs.biallelic_chr${}:position:A1:A2_recoded.raw.filtered.raw\n",
    "cat extract_chr${}.compact_filtered.r4.wgs.biallelic_chr${}:position:A1:A2_recoded.raw.filtered.raw"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "523d1836",
   "metadata": {},
   "source": [
    "## Remove related individuals and calculate allele frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b844123e-5c07-4a8d-b203-ff6add88a8e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2877131b-95b4-4e65-948c-83fa747cd81e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile var_keepnewUKB.txt\n",
    "chr${}:${Position}:${A1}:${A2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a2aea29-114c-49aa-8ce2-038196395745",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "module load plink\n",
    "plink2 --pfile ${WORK_DIR}/chr${}.compact_filtered.r4.wgs.biallelic \\\n",
    "--extract var_keepnewUKB.txt --make-bed --out adsp_varsnewUKB_chr${}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2bc33c6-8439-4ec2-9c7f-b162132f18dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "ancesty= pd.read_csv(\"${WORK_DIR}/FILTERED.merged_biallelic_${ANCESTRY}.psam\", sep = '\\t')\n",
    "ancestry.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "fd26995f-930e-4d40-85e1-74f6039beedc",
   "metadata": {},
   "outputs": [],
   "source": [
    "ancestry_keep = ${ANCESTRY} [[\"#FID\", \"IID\"]]\n",
    "ancestry_keep.to_csv(\"adsp_${ANCESTRY}_keep.txt\", sep=\"\\t\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f2f4664-6285-4364-9aad-709fa1c41270",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "module load plink/1.9\n",
    "plink --bfile adsp_varsnewUKB_chr${} --keep adsp_${ANCESTRY}_keep.txt --make-bed --out adsp_varsnewUKB_${ANCESTRY}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1af95e1-145f-40a6-98a5-27c00f05e025",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "module load plink/1.9  \n",
    "plink --bfile adsp_varsnewUKB_${ANCESTRY} --remove ${WORK_DIR}/REMOVE.FILTERED.merged_biallelic_${ANCESTRY}.related --make-bed --out adsp_varsnewUKB_${ANCESTRY}_unrelated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d66f3392-c33b-43ea-83c0-9294a8cded0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "module load plink/1.9\n",
    "plink --bfile adsp_varsnewUKB_${ANCESTRY}_unrelated --freq --out adsp_varsnewUKB_${ANCESTRY}_freq_unrelated\n",
    "cat adsp_varsnewUKB_${ANCESTRY}_freq_unrelated.frq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67da01ed-b3aa-4ef9-8e9b-aaa8b04e12f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "qc_covar = pd.read_csv(\"${WORK_DIR}/covars_for_QC.txt\", sep=\"\\t\")\n",
    "qc_covar.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "099f1c08-c6ee-4892-994d-87eede6a3a26",
   "metadata": {},
   "outputs": [],
   "source": [
    "qc_case = qc_covar[qc_covar[\"PHENO\"]==2]\n",
    "qc_case.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "7e4a4c28-a4cc-4d27-a5e4-4d3155a0f097",
   "metadata": {},
   "outputs": [],
   "source": [
    "qc_case_plink = qc_case[[\"FID\", \"IID\"]]\n",
    "qc_case_plink.to_csv(\"qc_case_plink.txt\", sep=\"\\t\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfa92cab-f5bc-4b61-ab06-1adb18ecb8c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "qc_control = qc_covar[qc_covar[\"PHENO\"]==1]\n",
    "qc_control.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "5970cffb-c3a8-4ab5-a2be-2138be7173b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "qc_control_plink = qc_control[[\"FID\", \"IID\"]]\n",
    "qc_control_plink.to_csv(\"qc_control_plink.txt\", sep=\"\\t\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad866a32-8bab-4ca8-a29c-bdccbc11d6af",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "module load plink/1.9\n",
    "plink --bfile adsp_varsnewUKB_${ANCESTRY}_unrelated --keep qc_${COHORT}_plink.txt --make-bed --out adsp_varsnewUKB_${ANCESTRY}_${COHORT}_unrelated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d7cab04-5ba7-419c-bb42-0919d7923d89",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "module load plink/1.9\n",
    "plink --bfile adsp_varsnewUKB_${ANCESTRY}_${COHORT}_unrelated --freq --out adsp_varsnewUKB_${ANCESTRY}_${COHORT}_unrelated_freq\n",
    "cat adsp_varsnewUKB_${ANCESTRY}_${COHORT}_unrelated_freq.frq"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b68b379b",
   "metadata": {},
   "source": [
    "# Query ADSP for APOE genotyping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db44e16c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "from functools import reduce\n",
    "import argparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4015bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile var_keepapoe.txt\n",
    "chr19:44908684:T:C\n",
    "chr19:44908822:C:T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82084f9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "plink2 --pfile ${WORK_DIR}/chr19.compact_filtered.r4.wgs.biallelic \\\n",
    "--extract var_keepapoe.txt --make-bed --out adsp_vars_chr19_apoe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4415afe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "ancestry= pd.read_csv(\"${WORK_DIR}/FILTERED.merged_biallelic_${ANCESTRY}.psam\", sep = '\\t')\n",
    "ancestry.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbb65dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "ancestry_keep = ${ANCESTRY}[[\"#FID\", \"IID\"]]\n",
    "ancestry_keep.to_csv(\"adsp_${ANCESTRY}_keep.txt\", sep=\"\\t\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5a7b6d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "module load plink/1.9\n",
    "plink --bfile adsp_vars_chr19_apoe --keep adsp_${ANCESTRY}_keep.txt --make-bed --out adsp_vars_${ANCESTRY}_apoe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b9b7753",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "module load plink/1.9  \n",
    "plink --bfile adsp_vars_${ANCESTRY}_apoe --remove ${WORK_DIR}/REMOVE.FILTERED.merged_biallelic_${ANCESTRY}.related --make-bed --out adsp_vars_${ANCESTRY}_apoe_unrelated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34b42344",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "module load plink/1.9\n",
    "plink --bfile adsp_vars_${ANCESTRY}_apoe_unrelated --recode compound-genotypes --out adsp_vars_${ANCESTRY}_apoe_unrelated_recode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d41e1e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile APOE_genotypes_PLINK_ped.py\n",
    "#!/bin/env python\n",
    "\n",
    "# Determine APOE genotypes from PLINK output\n",
    "    # January 2021\n",
    "    # Mary B. Makarious, Makayla Portley, and Cornelis Blauwendraat (LNG/NIA/NINDS/NIH)\n",
    "    # Script usage:\n",
    "        # python APOE_genotypes_PLINK_ped.py -i INPUT.ped -o OUTPUT_NAME\n",
    "\n",
    "## APOE Information\n",
    "# https://www.snpedia.com/index.php/APOE\n",
    "\n",
    "    # |          APOE GENO         \t| rs429358 \t| rs7412 \t|             COMBINED             \t|\n",
    "    # |:--------------------------:\t|:--------:\t|:------:\t|:--------------------------------:\t|\n",
    "    # |            e1/e1           \t|    CC    \t|   TT   \t|               CC_TT              \t|\n",
    "    # |            e1/e2           \t|    CT    \t|   TT   \t|          CT_TT or TC_TT          \t|\n",
    "    # |            e1/e4           \t|    CC    \t|   CT   \t|          CC_CT or CC_TC          \t|\n",
    "    # |            e2/e2           \t|    TT    \t|   TT   \t|               TT_TT              \t|\n",
    "    # |            e2/e3           \t|    TT    \t|   TC   \t|          TT_TC or TT_CT          \t|\n",
    "    # | e2/e4 or e1/e3 (Ambiguous) \t|    TC    \t|   TC   \t| TC_TC or CT_CT or TC_CT or CT_TC \t|\n",
    "    # |            e3/e3           \t|    TT    \t|   CC   \t|               TT_CC              \t|\n",
    "    # |            e3/e4           \t|    TC    \t|   CC   \t|          TC_CC or CT_CC          \t|\n",
    "    # |            e4/e4           \t|    CC    \t|   CC   \t|               CC_CC              \t|\n",
    "\n",
    "# Import the necessary packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "from functools import reduce\n",
    "import argparse\n",
    "\n",
    "# Initialize parser and add arguments\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"--input\", \"-i\", help=\"Input file name (with suffix)\")\n",
    "parser.add_argument(\"--output\", \"-o\", help=\"Desired output name (without suffix)\")\n",
    "args = parser.parse_args()\n",
    "\n",
    "# Read in the .ped file and force column names\n",
    "header_text = [\"FID\", \"IID\", \"PAT\", \"MAT\", \"SEX\", \"PHENO\", \"rs429358\", \"rs7412\"]\n",
    "input_ped_df = pd.read_csv(args.input, sep = \" \", header=None, names=header_text)\n",
    "\n",
    "# Make a combined column, gluing the genotypes from the rs429358 and rs7412 columns\n",
    "input_ped_df['rs429358_rs7412'] = input_ped_df['rs429358'].astype(str)+'_'+input_ped_df['rs7412']\n",
    "\n",
    "# Initialize a dictionary with the genotypes to search what genotype the alleles generate\n",
    "apoe_genotypes_dict = {\n",
    "    'CC_TT' : 'e1/e1',\n",
    "    'CT_TT' : 'e1/e2',\n",
    "    'TC_TT' : 'e1/e2',\n",
    "    'CC_CT' : 'e1/e4',\n",
    "    'CC_TC' : 'e1/e4',\n",
    "    'TT_TT' : 'e2/e2',\n",
    "    'TT_TC' : 'e2/e3',\n",
    "    'TT_CT' : 'e2/e3',\n",
    "    'TC_TC' : 'e2/e4 or e1/e3',\n",
    "    'CT_CT' : 'e2/e4 or e1/e3',\n",
    "    'TC_CT' : 'e2/e4 or e1/e3',\n",
    "    'CT_TC' : 'e2/e4 or e1/e3',\n",
    "    'TT_CC' : 'e3/e3',\n",
    "    'TC_CC' : 'e3/e4',\n",
    "    'CT_CC' : 'e3/e4',\n",
    "    'CC_CC' : 'e4/e4'\n",
    "}\n",
    "\n",
    "# Map the combined column to the dictionary to extract the genotypes\n",
    "input_ped_df['APOE_GENOTYPE'] = input_ped_df['rs429358_rs7412'].map(apoe_genotypes_dict)\n",
    "\n",
    "# If any of the combined alleles weren't in the dictionary, the dataframe now has NaN values\n",
    "# This happens if you have a 0 or missingness somewhere, resulting in an unsure genotype call\n",
    "# Replace these with something more useful, and state the APOE genotype as \"unknown\"\n",
    "input_ped_df.replace(np.nan, 'unknown', regex=True, inplace=True)\n",
    "\n",
    "# Make a file of just the FID, IID, SEX, PHENO, and APOE genotype\n",
    "subset_geno_df = input_ped_df.drop(columns=['PAT', 'MAT', 'rs429358', 'rs7412'])\n",
    "\n",
    "## Generate counts\n",
    "# Generate APOE genotype counts and percentages for entire dataset\n",
    "counts_df = pd.DataFrame(subset_geno_df['APOE_GENOTYPE'].value_counts().reset_index())\n",
    "counts_df.columns = ['APOE_GENOTYPE', 'TOTAL_COUNT']\n",
    "counts_df['TOTAL_PERCENT'] = counts_df['TOTAL_COUNT'] / subset_geno_df.shape[0] * 100\n",
    "\n",
    "# Separate out into cases, controls, and missing phenotypes\n",
    "    # This assumes controls=1 and cases=2 (missing is -9)\n",
    "\n",
    "# Subset by phenotype\n",
    "missing_pheno_df = subset_geno_df[subset_geno_df['PHENO'] == -9]\n",
    "controls_df = subset_geno_df[subset_geno_df['PHENO'] == 1]\n",
    "cases_df = subset_geno_df[subset_geno_df['PHENO'] == 2]\n",
    "\n",
    "# Generate APOE genotype counts and percentages for missing phenotypes\n",
    "missing_pheno_counts_df = pd.DataFrame(missing_pheno_df['APOE_GENOTYPE'].value_counts().reset_index())\n",
    "missing_pheno_counts_df.columns = ['APOE_GENOTYPE', 'MISSING_PHENO_COUNT']\n",
    "missing_pheno_counts_df['MISSING_PHENO_PERCENT'] = missing_pheno_counts_df['MISSING_PHENO_COUNT'] / missing_pheno_df.shape[0] * 100\n",
    "\n",
    "# Generate APOE genotype counts and percentages for controls\n",
    "controls_counts_df = pd.DataFrame(controls_df['APOE_GENOTYPE'].value_counts().reset_index())\n",
    "controls_counts_df.columns = ['APOE_GENOTYPE', 'CONTROLS_COUNT']\n",
    "controls_counts_df['CONTROLS_PERCENT'] = controls_counts_df['CONTROLS_COUNT'] / controls_df.shape[0] * 100\n",
    "\n",
    "# Generate APOE genotype counts and percentages for cases\n",
    "cases_counts_df = pd.DataFrame(cases_df['APOE_GENOTYPE'].value_counts().reset_index())\n",
    "cases_counts_df.columns = ['APOE_GENOTYPE', 'CASES_COUNT']\n",
    "cases_counts_df['CASES_PERCENT'] = cases_counts_df['CASES_COUNT'] / cases_df.shape[0] * 100\n",
    "\n",
    "# Merge the dataframes together for final summary counts file\n",
    "dataframes_tomerge = [counts_df, missing_pheno_counts_df, controls_counts_df, cases_counts_df]\n",
    "merged_summary_df = reduce(lambda left,right: pd.merge(left,right,on='APOE_GENOTYPE'), dataframes_tomerge)\n",
    "\n",
    "## Export\n",
    "complete_df_output = args.output + \".APOE_GENOTYPES.csv\"\n",
    "counts_df_output = args.output + \".APOE_SUMMARY.csv\"\n",
    "\n",
    "# Save out the complete dataframe as a .csv\n",
    "print(f\"Your complete genotype file has been saved here: {complete_df_output}\")\n",
    "subset_geno_df.to_csv(complete_df_output, index=False)\n",
    "\n",
    "# Save out the counts as a .csv\n",
    "print(f\"The summary counts have been saved here: {counts_df_output}\")\n",
    "merged_summary_df.to_csv(counts_df_output, index=False)\n",
    "\n",
    "# Done!\n",
    "print(\"Thanks!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aaf0d98",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "python APOE_genotypes_PLINK_ped.py -i adsp_vars_${ANCESTRY}_apoe_unrelated_recode.ped -o adsp_vars_${ANCESTRY}_apoe_unrelated_recode_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50bd678d",
   "metadata": {},
   "outputs": [],
   "source": [
    "qc_covar = pd.read_csv(\"${WORK_DIR}/covars_for_QC.txt\", sep=\"\\t\")\n",
    "qc_covar.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b900d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "qc_cases = qc_covar[qc_covar[\"PHENO\"]==2]\n",
    "qc_cases.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54d3bf29",
   "metadata": {},
   "outputs": [],
   "source": [
    "qc_cases_plink = qc_cases[[\"FID\", \"IID\"]]\n",
    "qc_cases_plink.to_csv(\"qc_cases_plink.txt\", sep=\"\\t\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "968b946a",
   "metadata": {},
   "outputs": [],
   "source": [
    "qc_control = qc_covar[qc_covar[\"PHENO\"]==1]\n",
    "qc_control.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9812ec8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "qc_control_plink = qc_control[[\"FID\", \"IID\"]]\n",
    "qc_control_plink.to_csv(\"qc_control_plink.txt\", sep=\"\\t\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2153bae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the CSV file into a DataFrame\n",
    "data = pd.read_csv('adsp_vars_${ANCESTRY}_apoe_unrelated_recode_test.APOE_GENOTYPES.csv')\n",
    "\n",
    "# Read the txt file into a DataFrame with tab delimiter\n",
    "qc_${COHORT} = pd.read_csv('qc_${COHORT}_plink.txt', delimiter='\\t')\n",
    "\n",
    "# Merge the two DataFrames based on FID and IID columns\n",
    "merged_data = pd.merge(data, qc_${COHORT}, on=['FID', 'IID'])\n",
    "\n",
    "# Save the merged DataFrame as a new CSV file\n",
    "merged_data.to_csv('adsp_vars_${ANCESTRY}_${COHORT}_apoe_unrelated.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07fe078b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('adsp_vars_${ANCESTRY}_${COHORT}_apoe_unrelated.csv', 'r') as file:\n",
    "    # Read the content\n",
    "    content = file.read()\n",
    "    # Count occurrences of 'GENOTYPE'\n",
    "    count = content.count('${GENOTYPE}')\n",
    "\n",
    "# Print the count\n",
    "print(\"Word count of '${GENOTYPE}' in adsp_vars_${ANCESTRY}_${COHORT}_apoe_unrelated.csv:\", count)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53f6076a",
   "metadata": {},
   "source": [
    "# Query ADSP for demographic and phenotypic data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a7e2315",
   "metadata": {},
   "source": [
    "## Demographic data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53589ee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb016598",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "plink2 --pfile ${WORK_DIR}/FILTERED.merged_biallelic_${ANCESTRY} --remove ${WORK_DIR}/REMOVE.FILTERED.merged_biallelic_${ANCESTRY}.related --make-bed --out ADSP_${ANCESTRY}_unrelated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0fbd493",
   "metadata": {},
   "outputs": [],
   "source": [
    "!awk '{print $1, $2}' ADSP_${ANCESTRY}_unrelated.fam > ADSP_${ANCESTRY}_unrelated_subset.fam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e45d9445",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge files for each group\n",
    "!cat ADSP_AAC_unrelated_subset.fam ADSP_AFR_unrelated_subset.fam ADSP_AJ_unrelated_subset.fam ADSP_AMR_unrelated_subset.fam ADSP_CAH_unrelated_subset.fam ADSP_CAS_unrelated_subset.fam ADSP_EAS_unrelated_subset.fam ADSP_EUR_unrelated_subset.fam ADSP_FIN_unrelated_subset.fam ADSP_MDE_unrelated_subset.fam ADSP_SAS_unrelated_subset.fam > mergedIDS_file.fam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d90e1075",
   "metadata": {},
   "outputs": [],
   "source": [
    "qc_covarsex = pd.read_csv(\"${WORK_DIR}/covars_for_QC.txt\", sep=\"\\t\")\n",
    "qc_covarsex.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "081cc15f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!grep -w -Ff <(awk '{print $1}' mergedIDS_file.fam) ${WORK_DIR}/covars_for_QC.txt > filtered_covars_for_QC.txt\n",
    "!awk '$6 == 1 {print > \"controls.txt\"} $6 == 2 {print > \"cases.txt\"}' filtered_covars_for_QC.txt\n",
    "!wc controls.txt\n",
    "!wc cases.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cecd332",
   "metadata": {},
   "outputs": [],
   "source": [
    "!awk '$7 == 1 {print > \"male_control.txt\"} $7 == 2 {print > \"female_controls.txt\"}' controls.txt\n",
    "!wc male_control.txt\n",
    "!wc female_controls.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93049bd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "!awk '$7 == 1 {print > \"male_case.txt\"} $7 == 2 {print > \"female_case.txt\"}' cases.txt\n",
    "!wc male_case.txt\n",
    "!wc female_case.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7542302",
   "metadata": {},
   "outputs": [],
   "source": [
    "!awk '{sum += $8; sumsq += ($8)^2; count++} END {avg = sum/count; sd = sqrt(sumsq/count - (avg)^2); print \"Femalecontrol: Average Age =\", avg, \"SD =\", sd}' female_controls.txt\n",
    "!awk '{sum += $8; sumsq += ($8)^2; count++} END {avg = sum/count; sd = sqrt(sumsq/count - (avg)^2); print \"Malecontrols: Average Age =\", avg, \"SD =\", sd}' male_control.txt\n",
    "!awk '{sum += $8; sumsq += ($8)^2; count++} END {avg = sum/count; sd = sqrt(sumsq/count - (avg)^2); print \"Femalecase: Average Age =\", avg, \"SD =\", sd}' female_case.txt\n",
    "!awk '{sum += $8; sumsq += ($8)^2; count++} END {avg = sum/count; sd = sqrt(sumsq/count - (avg)^2); print \"Malecase: Average Age =\", avg, \"SD =\", sd}' male_case.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba9542df",
   "metadata": {},
   "source": [
    "## Phenotype data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9142cdd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "module load plink\n",
    "plink2 -pfile ${WORK_DIR}/chr${}.compact_filtered.r4.wgs.biallelic --snps chr${}:position:A1:A2 --make-bed --out chr${}_variant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc6a4091",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "%%bash\n",
    "module load plink\n",
    "plink2 --bfile chr${}_variant  --recode A --out chr${}_variant_recoded\n",
    "awk '$7 == 0 || $7 == 1' chr${}_variant_recoded.raw > chr${}_variant_recoded.raw.filtered.raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ab4e8ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "module load plink/1.9\n",
    "plink --bfile chr${}_variant --keep qc_${COHORT}_plink.txt --make-bed --out chr${}_variant_${COHORT}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5c634f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the .fam file\n",
    "fam_file = 'chr${}_variant_${COHORT}.fam'\n",
    "fam_df = pd.read_csv(fam_file, delim_whitespace=True, header=None, usecols=[0, 1], names=['FID', 'IID'])\n",
    "\n",
    "# Load the .raw file without headers, taking the first two columns\n",
    "raw_file = 'chr${}_variant_recoded.raw.filtered.raw'\n",
    "raw_df = pd.read_csv(raw_file, delim_whitespace=True, header=None, usecols=[0, 1], names=['FID', 'IID'])\n",
    "\n",
    "# Merge the dataframes on FID and IID\n",
    "merged_df = pd.merge(fam_df, raw_df, on=['FID', 'IID'], how='inner')\n",
    "\n",
    "# Save the result back to a .fam file\n",
    "merged_df.to_csv('chr${}_variant_${COHORT}_filtered.fam', sep=' ', header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a25291e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile ${COHORT}_sampleids.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c636c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the qc_covar file\n",
    "qc_covar = pd.read_csv(\"${WORK_DIR}/covars_for_QC.txt\", sep=\"\\t\")\n",
    "\n",
    "# Load the Cohort_sampleids file without headers\n",
    "cohort_sampleids = pd.read_csv(\"${COHORT}_sampleids.txt\", delim_whitespace=True, header=None, names=['FID', 'IID'])\n",
    "\n",
    "# Merge the dataframes on FID and IID\n",
    "merged_df = pd.merge(qc_covar, cohort_sampleids, on=['FID', 'IID'], how='inner')\n",
    "\n",
    "# Save the result back to a file\n",
    "merged_df.to_csv(\"qc_covar_${COHORT}_sampleids.txt\", sep=\"\\t\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25f8145c",
   "metadata": {},
   "source": [
    "# Query ADSP for resilience and protective variants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47e423ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "from functools import reduce\n",
    "import argparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6c260b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import os\n",
    "\n",
    "# Define variations\n",
    "variations = [\n",
    "    \"chr${}:${Position}:${A1}:${A2}\"\n",
    "    ]\n",
    "# Define file directory\n",
    "file_dir = \"${WORK_DIR}\"\n",
    "\n",
    "# Iterate over each variation\n",
    "for variation in variations:\n",
    "    # Extract chromosome from variation\n",
    "    chromosome = variation.split(\":\")[0]\n",
    "    # Construct file path\n",
    "    file_path = f\"{file_dir}{chromosome}.compact_filtered.r4.wgs.biallelic.pvar\"\n",
    "    # Check if file exists\n",
    "    if os.path.exists(file_path):\n",
    "        # Grep for variation in file\n",
    "        print(f\"Searching for variation {variation} in file {file_path}\")\n",
    "        subprocess.run([\"grep\", \"-e\", variation, file_path])\n",
    "    else:\n",
    "        print(f\"File not found: {file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17e84bf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import os\n",
    "\n",
    "# Define the variants\n",
    "variants = [\n",
    "    \"chr${}:${Position}:${A1}:${A2}\"\n",
    "    ]\n",
    "\n",
    "# Define the directory containing the files for each chromosome\n",
    "file_dir = \"${WORK_DIR}\"\n",
    "\n",
    "# List to store the names of the created files\n",
    "created_files = []\n",
    "\n",
    "# Loop over each variant\n",
    "for variant in variants:\n",
    "    # Extract chromosome from variant\n",
    "    chromosome = variant.split(\":\")[0]\n",
    "    \n",
    "    # Define the file for the current chromosome\n",
    "    file = f\"{chromosome}.compact_filtered.r4.wgs.biallelic\"\n",
    "\n",
    "    # Write the variant to a temporary file\n",
    "    with open(\"temp_variant.txt\", \"w\") as f:\n",
    "        f.write(variant)\n",
    "\n",
    "    # Construct the output file name\n",
    "    output_file = f\"extract_{variant.replace(':', '_')}\"\n",
    "\n",
    "    # Extract the variant\n",
    "    subprocess.run([\n",
    "        \"plink2\",\n",
    "        \"--pfile\",\n",
    "        os.path.join(file_dir, file),\n",
    "        \"--extract\",\n",
    "        \"temp_variant.txt\",\n",
    "        \"--make-bed\",\n",
    "        \"--out\",\n",
    "        output_file\n",
    "    ])\n",
    "\n",
    "    # Add the name of the created file to the list\n",
    "    created_files.append(output_file)\n",
    "\n",
    "    # Remove the temporary file\n",
    "    os.remove(\"temp_variant.txt\")\n",
    "\n",
    "# Run the plink2 command for all created files\n",
    "for file_name in created_files:\n",
    "    subprocess.run([\n",
    "        \"plink2\",\n",
    "        \"--bfile\",\n",
    "        file_name,\n",
    "        \"--recode\",\n",
    "        \"A\",\n",
    "        \"--out\",\n",
    "        f\"{file_name}_recoded\"\n",
    "    ])\n",
    "\n",
    "# Filter the recoded files\n",
    "for file_name in created_files:\n",
    "    recoded_file = f\"{file_name}_recoded.raw\"\n",
    "    if os.path.exists(recoded_file):\n",
    "        with open(f\"{file_name}_filtered.raw\", \"w\") as f_out:\n",
    "            with open(recoded_file, \"r\") as f_in:\n",
    "                for line in f_in:\n",
    "                    if line.strip().split()[6] in [\"0\", \"1\"]:\n",
    "                        f_out.write(line)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "117770d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/bin/bash\n",
    "\n",
    "# Define ancestries and genotypes\n",
    "declare -a ancestries=('eur' 'afr' 'amr' 'eas' 'sas' 'mde' 'aj' 'fin' 'aac' 'cas' 'cah')\n",
    "declare -a genotypes=('00_00_unknown' '00_CC_unknown' '00_TC_unknown' 'TT_00_unknown' 'CT_00_unknown' 'CC_00_unknown'\n",
    "    'e1_e1' 'e1_e2' 'e1_e4' 'e2_e2' 'e2_e3' 'e2e4_or_e1e3' 'e3_e3' 'e3_e4' 'e4_e4')\n",
    "\n",
    "# Path to the directory containing the CSV files\n",
    "csv_dir='${WORK_DIR}'\n",
    "\n",
    "# Path to the current directory for raw files\n",
    "raw_dir='./'\n",
    "\n",
    "# Create a temporary file to store intermediate results\n",
    "tmp_file=$(mktemp)\n",
    "\n",
    "# Get total number of files for progress tracking\n",
    "total_files=$(ls $csv_dir | grep -E \"^filtered_.*_adsp_vars_.*_${COHORT}_apoe_unrelated.csv\" | wc -l)\n",
    "\n",
    "# Counter for tracking progress\n",
    "progress_counter=0\n",
    "\n",
    "# Iterate over each file in the directory\n",
    "for file_name in $(ls $csv_dir); do\n",
    "    # Check if the file is a CSV file for the specified genotypes and ancestries\n",
    "    if [[ $file_name =~ ^filtered_.*_adsp_vars_.*_${COHORT}_apoe_unrelated.csv ]]; then\n",
    "        # Read the CSV file into a DataFrame\n",
    "        filtered_df=$(cat $csv_dir/$file_name)\n",
    "\n",
    "        # Iterate over all files in the directory again\n",
    "        for raw_file in $(ls $raw_dir); do\n",
    "            # Check if the file is one of the raw files\n",
    "            if [[ $raw_file == *_filtered.raw ]]; then\n",
    "                # Extract variations from the raw file name\n",
    "                variations=$(echo $raw_file | cut -d'_' -f2-5)\n",
    "\n",
    "                # Read the raw file into a DataFrame, specifying the tab as the separator\n",
    "                adsp_df=$(cat $raw_dir/$raw_file)\n",
    "\n",
    "                # Filter rows where the first two columns match in both DataFrames\n",
    "                filtered_ids=$(comm -12 <(echo \"$filtered_df\" | awk -F',' '{print $1$2}' | sort) <(echo \"$adsp_df\" | awk -F'\\t' '{print $1$2}' | sort))\n",
    "\n",
    "                # Calculate the count of filtered ids (number of lines), handle the case when there are no common sample IDs\n",
    "                if [ -z \"$filtered_ids\" ]; then\n",
    "                    count=0\n",
    "                else\n",
    "                    count=$(echo \"$filtered_ids\" | wc -l)\n",
    "                fi\n",
    "\n",
    "                # Append the results to the temporary file\n",
    "                for genotype in \"${genotypes[@]}\"; do\n",
    "                    for ancestry in \"${ancestries[@]}\"; do\n",
    "                        if [[ $file_name == \"filtered_${genotype}_adsp_vars_${ancestry}_cases_apoe_unrelated.csv\" ]]; then\n",
    "                            echo \"$genotype,$ancestry,$variations,$count\" >> $tmp_file\n",
    "                        fi\n",
    "                    done\n",
    "                done\n",
    "            fi\n",
    "        done\n",
    "    fi\n",
    "    # Update progress counter\n",
    "    progress_counter=$((progress_counter+1))\n",
    "    echo \"Processed $progress_counter/$total_files files\"\n",
    "done\n",
    "\n",
    "# Define headers for the final CSV file\n",
    "headers='Genotype,Ancestry,Variation,Count'\n",
    "\n",
    "# Save results to a final CSV file\n",
    "echo \"$headers\" > final${COHORT}_counts.csv\n",
    "cat $tmp_file >> final${COHORT}_counts.csv\n",
    "\n",
    "# Remove the temporary file\n",
    "rm $tmp_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63770106",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Define the custom row order\n",
    "custom_row_order = [\n",
    "    '00_00_unknown',\n",
    "    '00_CC_unknown',\n",
    "    '00_TC_unknown',\n",
    "    'TT_00_unknown',\n",
    "    'CT_00_unknown',\n",
    "    'CC_00_unknown',\n",
    "    'e1_e1',\n",
    "    'e1_e2',\n",
    "    'e1_e4',\n",
    "    'e2_e2',\n",
    "    'e2_e3',\n",
    "    'e2e4_or_e1e3',\n",
    "    'e3_e3',\n",
    "    'e3_e4',\n",
    "    'e4_e4',\n",
    "    'Total'\n",
    "]\n",
    "\n",
    "# Define the new order of columns\n",
    "new_column_order = ['Genotype', 'Total', 'eur', 'afr', 'amr', 'eas', 'sas', 'mde', 'aj', 'fin', 'aac', 'cas', 'cah']\n",
    "\n",
    "# Specify the directory containing the files\n",
    "directory = '${WORK_DIR}'\n",
    "\n",
    "# Get a list of all files in the directory\n",
    "file_list = os.listdir(directory)\n",
    "\n",
    "for file_name in file_list:\n",
    "    # Check if the file is a CSV file\n",
    "    if file_name.endswith('.csv'):\n",
    "        # Read the CSV file into a DataFrame\n",
    "        file_path = os.path.join(directory, file_name)\n",
    "        df = pd.read_csv(file_path)\n",
    "\n",
    "        # Create a dictionary to map each row to its desired position\n",
    "        row_mapping = {row: index for index, row in enumerate(custom_row_order)}\n",
    "\n",
    "        # Apply the custom row order\n",
    "        df['row_order'] = df['Genotype'].map(row_mapping)\n",
    "        df = df.sort_values('row_order').drop('row_order', axis=1).reset_index(drop=True)\n",
    "\n",
    "        # Reorder the columns\n",
    "        df = df[new_column_order]\n",
    "\n",
    "        # Save the DataFrame back to a CSV file with the .reordered.csv suffix\n",
    "        new_file_name = os.path.splitext(file_name)[0] + '.reordered.csv'\n",
    "        new_file_path = os.path.join(directory, new_file_name)\n",
    "        df.to_csv(new_file_path, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e756693f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the CSV file into a pandas DataFrame\n",
    "df = pd.read_csv('final${COHORT}_counts.csv')\n",
    "\n",
    "# Define specific total counts for each ancestry\n",
    "total_counts = {\n",
    "    'eur': ${COUNT},\n",
    "    'afr': ${COUNT},\n",
    "    'amr': ${COUNT},\n",
    "    'eas': ${COUNT},\n",
    "    'sas': ${COUNT},\n",
    "    'mde': ${COUNT},\n",
    "    'aj': ${COUNT}7,\n",
    "    'fin': ${COUNT},\n",
    "    'aac': ${COUNT},\n",
    "    'cas': ${COUNT},\n",
    "    'cah': ${COUNT}\n",
    "}\n",
    "\n",
    "# Iterate over unique variations\n",
    "for variation in df['Variation'].unique():\n",
    "    # Create a subset of the DataFrame for the current variation\n",
    "    subset = df[df['Variation'] == variation]\n",
    "\n",
    "    # Pivot the subset to create the desired table\n",
    "    pivot_table = subset.pivot(index='Genotype', columns='Ancestry', values='Count')\n",
    "\n",
    "    # Add a total row for the table\n",
    "    pivot_table.loc['Total'] = pivot_table.sum()\n",
    "\n",
    "    # Add total counts at the end of each ancestry column\n",
    "    for ancestry, total_count in total_counts.items():\n",
    "        pivot_table.loc['Total', ancestry] = total_count\n",
    "\n",
    "    # Calculate percentage for each value based on total count for each ancestry\n",
    "    pivot_table_percentage = pivot_table.div(pivot_table.loc['Total']) * 100\n",
    "\n",
    "    # Replace \"NaN\" values with 0\n",
    "    pivot_table_percentage = pivot_table_percentage.fillna(0)\n",
    "\n",
    "    # Combine the original counts with the percentages\n",
    "    pivot_table_combined = pivot_table.astype(str) + ',' + pivot_table_percentage.round(2).astype(str) + '%'\n",
    "\n",
    "    # Remove \",100.0%\" from the total row\n",
    "    pivot_table_combined.loc['Total'] = pivot_table_combined.loc['Total'].str.replace(',100.0%', '')\n",
    "\n",
    "    # Remove \",0.0%\" from the total row\n",
    "    pivot_table_combined.loc['Total'] = pivot_table_combined.loc['Total'].str.replace(',0.0%', '')\n",
    "    \n",
    "    # Save the pivot_table_combined to a new CSV file\n",
    "    pivot_table_combined.to_csv(f'${COHORT}_{variation}.csv')\n",
    "\n",
    "    # Print a message indicating the file has been saved\n",
    "    print(f'Table for Variation: {variation} saved to ${COHORT}_{variation}.csv')\n",
    "    print('\\n')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python/3.10",
   "language": "python",
   "name": "py3.10"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
