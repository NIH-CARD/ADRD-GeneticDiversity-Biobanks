{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f48f4bda",
   "metadata": {},
   "source": [
    "# PRS \n",
    "\n",
    "* **Project:** ADRD Genetic Diversity in Biobanks\n",
    "* **Version:** Python/3.9 and 3.10\n",
    "* **Last Updated:** 10-FEB-2025\n",
    "\n",
    "## Notebook Overview\n",
    "Calculate polygenic risk score and perform logistic regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f3c15dd",
   "metadata": {},
   "source": [
    "# Query ADSP to calculate polygenic risk score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eaf304e2-6cfe-4a98-b211-ea94aa0a3278",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "from functools import reduce\n",
    "import argparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faddf2ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Merge data\n",
    "%%bash\n",
    "module load plink/2.0\n",
    "\n",
    "# Define input and output directories\n",
    "INPUT_DIR=\"${WORK_DIR}/UNFILTERED_PLINK/\"  \n",
    "OUTPUT_DIR=\"${WORK_DIR}\" \n",
    "OUTPUT_PREFIX=\"merged_UNQC_Files\"  \n",
    "\n",
    "# Create a list file with full paths to .pgen files \n",
    "MERGE_LIST=\"$OUTPUT_DIR/pgen_list.txt\"\n",
    "\n",
    "for CHR in {1..22} X Y M; do\n",
    "    PGEN_FILE=\"${INPUT_DIR}/chr${CHR}.compact_filtered.r4.wgs.biallelic.pgen\"\n",
    "    if [[ -f \"$PGEN_FILE\" ]]; then\n",
    "        echo \"${INPUT_DIR}/chr${CHR}.compact_filtered.r4.wgs.biallelic\" >> \"$MERGE_LIST\"\n",
    "    fi\n",
    "done\n",
    "\n",
    "# Run PLINK2 to merge all .pgen, .pvar, and .psam files into one\n",
    "plink2 --pmerge-list \"$MERGE_LIST\" pfile \\\n",
    "       --make-pgen \\\n",
    "       --out \"${OUTPUT_DIR}/${OUTPUT_PREFIX}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c379b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "! awk '{print $1, $2}' ${WORK_DIR}/FID_IID_PHENO_EUR.fam > keep_samples.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "264ca8b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "module load plink/2.0\n",
    "\n",
    "# Define input and output directories\n",
    "INPUT_DIR=\"${WORK_DIR}\"\n",
    "OUTPUT_DIR=\"${WORK_DIR}\"\n",
    "OUTPUT_PREFIX=\"filtered_UNQC_Files\"\n",
    "\n",
    "\n",
    "\n",
    "# Filter dataset based on keep_samples.txt and convert to PLINK1 binary format (.bed, .bim, .fam)\n",
    "plink2 --pfile \"$INPUT_DIR/merged_UNQC_Files\" \\\n",
    "       --keep keep_samples.txt \\\n",
    "       --make-bed \\\n",
    "       --out \"$OUTPUT_DIR/$OUTPUT_PREFIX\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9df8892",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Check score file \n",
    "! cat AD_GRS_Kunkle_final_UNQC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cedf2382",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Run PRS\n",
    "%%bash\n",
    "module load plink/2.0\n",
    "\n",
    "plink2 --bfile ${WORK_DIR}/filtered_UNQC_Files \\\n",
    "       --score AD_GRS_Kunkle_final_UNQC\\\n",
    "       --memory 128000 \\\n",
    "       --out PRS_results_UNQC_final\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d927c298",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Merge PRS output with covariate file\n",
    "import pandas as pd\n",
    "\n",
    "# File paths\n",
    "prs_file = \"PRS_results_UNQC_final.sscore\"\n",
    "covars_file = \"${WORK_DIR}/covars_alldata_with999forAGRandRACE_PCA.txt\"\n",
    "output_file = \"merged_data_UNQC.txt\"\n",
    "\n",
    "# Load PRS file and fix column separation\n",
    "prs_df = pd.read_csv(prs_file, delim_whitespace=True, dtype=str)  \n",
    "prs_df.columns = prs_df.columns.str.strip()  \n",
    "\n",
    "# Rename '#FID' to 'FID' if needed\n",
    "if \"#FID\" in prs_df.columns:\n",
    "    prs_df.rename(columns={\"#FID\": \"FID\"}, inplace=True)\n",
    "\n",
    "# Load Covariates file\n",
    "covars_df = pd.read_csv(covars_file, sep=\"\\t\", dtype=str)\n",
    "covars_df.columns = covars_df.columns.str.strip()  \n",
    "\n",
    "# Print column names for debugging\n",
    "print(\"PRS File Columns:\", prs_df.columns.tolist())\n",
    "print(\"Covariates File Columns:\", covars_df.columns.tolist())\n",
    "\n",
    "# Ensure data types match before merging\n",
    "prs_df[\"FID\"] = prs_df[\"FID\"].astype(str)\n",
    "prs_df[\"IID\"] = prs_df[\"IID\"].astype(str)\n",
    "covars_df[\"FID\"] = covars_df[\"FID\"].astype(str)\n",
    "covars_df[\"IID\"] = covars_df[\"IID\"].astype(str)\n",
    "\n",
    "# Merge on both FID and IID\n",
    "merged_df = prs_df.merge(covars_df, on=[\"FID\", \"IID\"], how=\"inner\")\n",
    "\n",
    "# Save merged file\n",
    "merged_df.to_csv(output_file, sep=\"\\t\", index=False)\n",
    "\n",
    "print(f\"Merged file saved as: {output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f7af8d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Normalize score to Z-score\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Load the merged file\n",
    "file_path = \"merged_data_UNQC.txt\"\n",
    "df = pd.read_csv(file_path, sep=\"\\t\")\n",
    "\n",
    "# Ensure SCORE and PHENO are numeric\n",
    "df[\"SCORE1_AVG\"] = pd.to_numeric(df[\"SCORE1_AVG\"], errors=\"coerce\")\n",
    "df[\"PHENO\"] = pd.to_numeric(df[\"PHENO\"], errors=\"coerce\")\n",
    "\n",
    "# Compute mean and standard deviation for controls (PHENO == 1)\n",
    "mean_controls = df.loc[df[\"PHENO\"] == 1, \"SCORE1_AVG\"].mean()\n",
    "sd_controls = df.loc[df[\"PHENO\"] == 1, \"SCORE1_AVG\"].std()\n",
    "\n",
    "# Apply Z-score normalization\n",
    "df[\"SCORE_Z\"] = (df[\"SCORE1_AVG\"] - mean_controls) / sd_controls\n",
    "\n",
    "# Save the normalized dataset\n",
    "output_file = \"merged_data_zscore_UNQC.txt\"\n",
    "df.to_csv(output_file, sep=\"\\t\", index=False)\n",
    "\n",
    "print(f\"Z-score normalized data saved to: {output_file}\")\n",
    "print(f\"Mean (Controls PHENO=1): {mean_controls:.6f}, SD (Controls PHENO=1): {sd_controls:.6f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a297273a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Select the upper 25th percentile\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Load the file\n",
    "file_path = \"merged_data_zscore_UNQC.txt\"\n",
    "df = pd.read_csv(file_path, sep=\"\\t\")\n",
    "\n",
    "# Compute the 75th percentile threshold for SCORE_Z\n",
    "percentile_75 = df[\"SCORE_Z\"].quantile(0.75)\n",
    "\n",
    "# Select individuals in the upper 25th percentile\n",
    "selected_df = df[df[\"SCORE_Z\"] >= percentile_75]\n",
    "\n",
    "# Save the selected individuals\n",
    "output_file = \"selected_upper_25th_percentile_UNQC.txt\"\n",
    "selected_df.to_csv(output_file, sep=\"\\t\", index=False)\n",
    "\n",
    "print(f\"Upper 25th percentile threshold: {percentile_75:.6f}\")\n",
    "print(f\"Selected individuals saved to: {output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8ff36b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create pheno file\n",
    "! cut -f1,2,9 selected_upper_25th_percentile_UNQC.txt> 25th_percentile_pheno_UNQC_eur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d297d062",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Check the count of cases and controls\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Load the file\n",
    "file_path = \"${WORK_DIR}/25th_percentile_pheno_UNQC_eur\"\n",
    "\n",
    "# Read the file assuming it's tab-separated\n",
    "df = pd.read_csv(file_path, sep=\"\\t\")\n",
    "\n",
    "# Count the occurrences of 1 and 2 in the third column\n",
    "counts = df.iloc[:, 2].value_counts()\n",
    "\n",
    "# Print the counts\n",
    "print(f\"Control (1): {counts.get(1, 0)}\")\n",
    "print(f\"Case (2): {counts.get(2, 0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "315a1fbe",
   "metadata": {},
   "source": [
    "# Extract protective/disease-modifying variants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f9df8fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "module load plink/2.0\n",
    "\n",
    "# Define file directory\n",
    "FILE_DIR=\"${WORK_DIR}/UNFILTERED_PLINK/\"\n",
    "\n",
    "# Define variants\n",
    "VARIANTS=(\n",
    "    \"chr19:1043104:G:A\" \"chr21:26171645:A:G\" \"chr21:26171723:T:C\"\n",
    "    \"chr4:139008878:A:G\" \"chr11:121564878:T:C\" \"chr14:92466484:T:C\"\n",
    "    \"chr20:56422512:G:A\" \"chr7:143410783:C:A\" \"chr15:50709337:T:G\"\n",
    "    \"chr21:25897620:C:T\" \"chr16:81908423:C:G\" \"chr19:43100929:G:A\"\n",
    "    \"chr19:44905307:A:T\" \"chr2:215424292:C:T\" \"chr2:215386857:G:A\"\n",
    "    \"chr7:103472855:T:C\" \"chr19:44892887:C:T\" \"chr2:26135287:A:G\"\n",
    "    \"chr17:46275856:T:G\" \"chr19:3405594:T:A\" \"chr19:44908756:C:A\"\n",
    ")\n",
    "\n",
    "# List to store only successfully created files for merging\n",
    "MERGE_LIST=\"${WORK_DIR}/pmerge_list.txt\"\n",
    "> $MERGE_LIST  \n",
    "\n",
    "# Extract variants from original PLINK files\n",
    "for VARIANT in \"${VARIANTS[@]}\"; do\n",
    "    CHR=$(echo $VARIANT | cut -d\":\" -f1)\n",
    "    FILE=\"$FILE_DIR/$CHR.compact_filtered.r4.wgs.biallelic\"\n",
    "    TEMP_FILE=\"${WORK_DIR}/temp_variant.txt\"\n",
    "    OUTPUT_FILE=\"${WORK_DIR}/extract_$(echo $VARIANT | tr ':' '_')\"\n",
    "\n",
    "    # Write variant to a temporary file\n",
    "    echo $VARIANT > $TEMP_FILE\n",
    "\n",
    "    # Extract variant and create PLINK2 format (.pgen, .psam, .pvar)\n",
    "    plink2 --pfile \"$FILE\" --extract $TEMP_FILE --make-pgen --out $OUTPUT_FILE\n",
    "\n",
    "    # Remove temporary file\n",
    "    rm $TEMP_FILE\n",
    "done\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "194fd3af",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "module load plink/2.0\n",
    "\n",
    "# Define final merged output file\n",
    "MERGED_FILE=\"${WORK_DIR}/merged_variants\"\n",
    "\n",
    "# Check if merge list contains files\n",
    "if [[ ! -s ${WORK_DIR}/pmerge_list.txt ]]; then\n",
    "    echo \"❌ No extracted variants with .psam files found. Exiting.\"\n",
    "    exit 1\n",
    "fi\n",
    "\n",
    "# Merge only successfully extracted PLINK2 files\n",
    "plink2 --pmerge-list ${WORK_DIR}/pmerge_list.txt pfile --make-pgen --out $MERGED_FILE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9437c429",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "module load plink/2.0\n",
    "\n",
    "# Define the merged PGEN file\n",
    "MERGED_FILE=\"${WORK_DIR}/merged_variants\"\n",
    "\n",
    "# Convert to BED format\n",
    "plink2 --pfile $MERGED_FILE --make-bed --out $MERGED_FILE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1821258d",
   "metadata": {},
   "source": [
    "# Run glm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e9659ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "module load plink/2.0\n",
    "\n",
    "  plink2 \\\n",
    "    --bfile \"${WORK_DIR}/merged_variants\" \\\n",
    "    --double-id \\\n",
    "    --pheno \"${WORK_DIR}/25th_percentile_pheno_UNQC_eur\" \\\n",
    "    --adjust \\\n",
    "    --ci 0.95 \\\n",
    "    --covar \"${WORK_DIR}/selected_upper_25th_percentile_UNQC.txt\" \\\n",
    "    --covar-name SCORE_Z,SEX,AGE,PC1,PC2,PC3,PC4,PC5 \\\n",
    "    --threads 15 \\\n",
    "    --covar-variance-standardize \\\n",
    "    --out \"${WORK_DIR}/Logistic_FID_IID_PHENO_case_controls_UNQC_EUR\" \\\n",
    "    --glm omit-ref firth-fallback cols=+a1freq,+a1freqcc,+a1count,+totallele,+a1countcc,+totallelecc,+gcountcc,+err \\\n",
    "    --silent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d03049b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the data\n",
    "data = pd.read_csv('${WORK_DIR}/Logistic_FID_IID_PHENO_case_controls_UNQC_EUR.PHENO.glm.logistic.hybrid', sep='\\t')\n",
    "\n",
    "# Filter rows where TEST == 'ADD'\n",
    "add_filtered = data[data['TEST'] == 'ADD']\n",
    "\n",
    "# Save to a new file\n",
    "add_filtered.to_csv('${WORK_DIR}/ADD_filtered_EUR_PRS_25th_UNQC.txt', sep='\\t', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8058ebad",
   "metadata": {},
   "source": [
    "## Adjust by APOE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6d4a68d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# File paths\n",
    "selected_file = \"${WORK_DIR}/selected_upper_25th_percentile_UNQC.txt\"\n",
    "apoe_file = \"${WORK_DIR}/covars_alldata_with999forAGRandRACE_PCA_APOE012.txt\"\n",
    "output_file = \"${WORK_DIR}/selected_UNQC_with_APOE_status.txt\"\n",
    "\n",
    "# Load selected individuals file\n",
    "selected_df = pd.read_csv(selected_file, sep=\"\\t\", dtype=str)\n",
    "\n",
    "# Load APOE file\n",
    "apoe_df = pd.read_csv(apoe_file, sep=\"\\t\", dtype=str)\n",
    "\n",
    "# Merge files on FID and IID (keeping only individuals present in both files)\n",
    "merged_df = selected_df.merge(apoe_df[[\"FID\", \"IID\", \"APOE_STATUS_012\"]], on=[\"FID\", \"IID\"], how=\"left\")\n",
    "\n",
    "# Save the updated file\n",
    "merged_df.to_csv(output_file, sep=\"\\t\", index=False)\n",
    "\n",
    "print(f\"Merged file saved to: {output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63c0c708",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "module load plink/2.0\n",
    "\n",
    "  plink2 \\\n",
    "    --bfile \"${WORK_DIR}/merged_variants\" \\\n",
    "    --double-id \\\n",
    "    --pheno \"${WORK_DIR}/25th_percentile_pheno_UNQC_eur\" \\\n",
    "    --adjust \\\n",
    "    --ci 0.95 \\\n",
    "    --covar \"${WORK_DIR}/selected_UNQC_with_APOE_status.txt\" \\\n",
    "    --covar-name SCORE_Z,APOE_STATUS_012,SEX,AGE,PC1,PC2,PC3,PC4,PC5 \\\n",
    "    --threads 15 \\\n",
    "    --covar-variance-standardize \\\n",
    "    --out \"${WORK_DIR}/Logistic_FID_IID_PHENO_case_controls_UNQC_APOE_EUR\" \\\n",
    "    --glm omit-ref firth-fallback cols=+a1freq,+a1freqcc,+a1count,+totallele,+a1countcc,+totallelecc,+gcountcc,+err \\\n",
    "    --silent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d841050",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the data\n",
    "data = pd.read_csv('${WORK_DIR}/Logistic_FID_IID_PHENO_case_controls_UNQC_APOE_EUR.PHENO.glm.logistic.hybrid', sep='\\t')\n",
    "\n",
    "# Filter rows where TEST == 'ADD'\n",
    "add_filtered = data[data['TEST'] == 'ADD']\n",
    "\n",
    "# Save to a new file\n",
    "add_filtered.to_csv('${WORK_DIR}/ADD_filtered_EUR_PRS_25th_UNQC_APOE.txt', sep='\\t', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python/3.10",
   "language": "python",
   "name": "py3.10"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
